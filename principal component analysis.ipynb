{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e5de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2035c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5182b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7552782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7281069b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6742\n",
       "7    6265\n",
       "3    6131\n",
       "2    5958\n",
       "9    5949\n",
       "0    5923\n",
       "6    5918\n",
       "8    5851\n",
       "4    5842\n",
       "5    5421\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8618ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9cca98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37062</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "37062      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "37062      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b255f3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 102, 190, 219, 142,   0,\n",
       "          0,   0,   0,   0,   0,  39, 226, 154,  38,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 213, 252, 252, 155,   0,\n",
       "          0,   0,   0,   0,  97, 223, 252, 252, 149,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  64, 233, 252, 143,  94,\n",
       "         94,  94,  94, 220, 249, 252, 252, 154,   8,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 172, 227, 252,\n",
       "        252, 252, 253, 252, 252, 252, 153,  11,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36,  53,\n",
       "         53,  53, 253, 252, 252, 188,  11,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  99, 253, 252, 232,  66,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          3, 152, 253, 252,  68,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         28, 252, 253, 170,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
       "        208, 252, 253,  13,   0,   0,   0,   8,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  27,\n",
       "        252, 252, 253, 139, 133, 133, 133, 168,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  83, 204,\n",
       "        253, 253, 255, 253, 253, 253, 158, 106,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 203, 240, 240, 248, 252,\n",
       "        252, 252, 253, 150,  97,  13,   3,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 233, 252, 252, 252,\n",
       "        252, 132,  26,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  31,  84, 252, 252,\n",
       "        241,  19,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 252, 252,\n",
       "        238,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 252, 252,\n",
       "        168,   0,  29,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  45, 239, 252,\n",
       "        248, 152, 113,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 173, 252,\n",
       "        252, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  94, 240,\n",
       "        252, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  13,\n",
       "        196, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[37602,1:].values.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3988152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x287f0a52880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df.iloc[37602,1:].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8956db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae442eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7483cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d8b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a19b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c049b73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3dd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e47d875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68928477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "910d7c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc6f9d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 8, ..., 9, 7, 2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07d899e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12628    7\n",
       "37730    3\n",
       "39991    8\n",
       "8525     9\n",
       "8279     3\n",
       "        ..\n",
       "49914    2\n",
       "34428    4\n",
       "45810    9\n",
       "30357    7\n",
       "36568    2\n",
       "Name: label, Length: 12000, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104f0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bc438ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9458333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44ca6c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.96      0.98      0.97      1175\\n           1       0.95      0.99      0.97      1322\\n           2       0.94      0.93      0.94      1174\\n           3       0.92      0.95      0.94      1219\\n           4       0.95      0.93      0.94      1176\\n           5       0.93      0.92      0.93      1104\\n           6       0.96      0.98      0.97      1177\\n           7       0.95      0.94      0.94      1299\\n           8       0.98      0.89      0.93      1160\\n           9       0.91      0.93      0.92      1194\\n\\n    accuracy                           0.95     12000\\n   macro avg       0.95      0.95      0.95     12000\\nweighted avg       0.95      0.95      0.95     12000\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1323d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfb0d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1156,    0,    3,    2,    1,    2,    9,    1,    0,    1],\n",
       "       [   0, 1310,    8,    0,    2,    0,    1,    1,    0,    0],\n",
       "       [  10,   12, 1096,   19,    4,    2,   11,   12,    5,    3],\n",
       "       [   2,    1,   16, 1159,    0,   19,    2,    8,    6,    6],\n",
       "       [   2,   13,   14,    1, 1098,    1,    3,    5,    0,   39],\n",
       "       [   8,    2,    3,   37,    6, 1015,   16,    1,   10,    6],\n",
       "       [  10,    3,    3,    0,    1,    8, 1152,    0,    0,    0],\n",
       "       [   2,   19,    6,    4,   10,    0,    0, 1218,    1,   39],\n",
       "       [  11,   13,    9,   25,   11,   38,    4,    6, 1033,   10],\n",
       "       [   5,    0,    9,    8,   21,    3,    0,   32,    3, 1113]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8a77d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6cbdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec700c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trf = pca.fit_transform(x_train)\n",
    "x_test_trf = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ceb5e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 200)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_trf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16074675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_trf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0a4745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "516f7b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train_trf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a99afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = knn.predict(x_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70aef0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546666666666667"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a02740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2618333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3164166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8379166666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6784\\354957899.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_trf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_trf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prefer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[0;32m    777\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[0;32m    778\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \"\"\"\n\u001b[1;32m--> 600\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,785):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_train_trf = pca.fit_transform(x_train)\n",
    "    X_test_trf = pca.transform(x_test)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_trf,y_train)\n",
    "    y_pred = knn.predict(X_test_trf)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf91a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=None)\n",
    "x_train_trf = pca.fit_transform(x_train)\n",
    "x_test_trf = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b2cc9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.05702238190887057),\n",
       " (1, 0.09818964113280014),\n",
       " (2, 0.13567192269821737),\n",
       " (3, 0.16469803080538986),\n",
       " (4, 0.18997512157280108),\n",
       " (5, 0.21201815956470593),\n",
       " (6, 0.23145482616178847),\n",
       " (7, 0.2489989566526786),\n",
       " (8, 0.2644910704011301),\n",
       " (9, 0.2785772136577356),\n",
       " (10, 0.29203612115833727),\n",
       " (11, 0.3041891168630006),\n",
       " (12, 0.31541422353091586),\n",
       " (13, 0.3264371411833322),\n",
       " (14, 0.3367790501663457),\n",
       " (15, 0.34679972888328076),\n",
       " (16, 0.3562865659034001),\n",
       " (17, 0.36553212202165836),\n",
       " (18, 0.37450139100569335),\n",
       " (19, 0.38325660145689283),\n",
       " (20, 0.3916548716132785),\n",
       " (21, 0.39977906052959744),\n",
       " (22, 0.4074645308115231),\n",
       " (23, 0.41493225604278666),\n",
       " (24, 0.4221352455545666),\n",
       " (25, 0.429072043311715),\n",
       " (26, 0.4359492647338421),\n",
       " (27, 0.44259091115014837),\n",
       " (28, 0.44892841610511525),\n",
       " (29, 0.45509786636844807),\n",
       " (30, 0.4611443388560603),\n",
       " (31, 0.46706145006725136),\n",
       " (32, 0.4727921443427255),\n",
       " (33, 0.4784889467277536),\n",
       " (34, 0.4840970439163371),\n",
       " (35, 0.48949155548554435),\n",
       " (36, 0.4948431034473751),\n",
       " (37, 0.5000816241585843),\n",
       " (38, 0.5052195134896401),\n",
       " (39, 0.5100600649779213),\n",
       " (40, 0.514862379676446),\n",
       " (41, 0.5196123693554311),\n",
       " (42, 0.5242273404869133),\n",
       " (43, 0.5287616419821344),\n",
       " (44, 0.53324320440179),\n",
       " (45, 0.5376976806004878),\n",
       " (46, 0.5420886866974504),\n",
       " (47, 0.5464458365459653),\n",
       " (48, 0.5507522575883504),\n",
       " (49, 0.5549100227633325),\n",
       " (50, 0.5590335675768728),\n",
       " (51, 0.5631087496431616),\n",
       " (52, 0.5671114074356428),\n",
       " (53, 0.5710614879200844),\n",
       " (54, 0.5749593224149812),\n",
       " (55, 0.5788157093630082),\n",
       " (56, 0.5825574215161753),\n",
       " (57, 0.5862730880463797),\n",
       " (58, 0.5899197732065089),\n",
       " (59, 0.5935194491941044),\n",
       " (60, 0.5970906750486199),\n",
       " (61, 0.6005904072457856),\n",
       " (62, 0.604043336824178),\n",
       " (63, 0.6074851767753741),\n",
       " (64, 0.6109012147744514),\n",
       " (65, 0.6142672480091947),\n",
       " (66, 0.6176132883575968),\n",
       " (67, 0.6209055432731038),\n",
       " (68, 0.6241304458083241),\n",
       " (69, 0.6273098238225938),\n",
       " (70, 0.6304629457243022),\n",
       " (71, 0.6335918412161554),\n",
       " (72, 0.6366890256688152),\n",
       " (73, 0.6397278026688344),\n",
       " (74, 0.642759519649137),\n",
       " (75, 0.6457644515720259),\n",
       " (76, 0.648750154494191),\n",
       " (77, 0.65168595004055),\n",
       " (78, 0.6545962562165133),\n",
       " (79, 0.65746760609115),\n",
       " (80, 0.6603227762166229),\n",
       " (81, 0.6631744733105476),\n",
       " (82, 0.6659923220421743),\n",
       " (83, 0.6687978204509393),\n",
       " (84, 0.6716028574662113),\n",
       " (85, 0.6744042355857944),\n",
       " (86, 0.6771753049547741),\n",
       " (87, 0.6799393506632855),\n",
       " (88, 0.6826660718679856),\n",
       " (89, 0.6853577159538422),\n",
       " (90, 0.6880389210811321),\n",
       " (91, 0.6906887583743898),\n",
       " (92, 0.6933181208845952),\n",
       " (93, 0.6959287556430136),\n",
       " (94, 0.6985110272432419),\n",
       " (95, 0.7010594016510532),\n",
       " (96, 0.7035859696178121),\n",
       " (97, 0.7061026392284951),\n",
       " (98, 0.7085708713882737),\n",
       " (99, 0.7110222828454229),\n",
       " (100, 0.7134594641449258),\n",
       " (101, 0.715854668225963),\n",
       " (102, 0.7182460684929124),\n",
       " (103, 0.7206122806859977),\n",
       " (104, 0.7229466940925424),\n",
       " (105, 0.7252543707043624),\n",
       " (106, 0.7275415898756605),\n",
       " (107, 0.7297755524188297),\n",
       " (108, 0.7319943761908491),\n",
       " (109, 0.7341885289789591),\n",
       " (110, 0.7363701875348242),\n",
       " (111, 0.7385346723497608),\n",
       " (112, 0.7406817240241136),\n",
       " (113, 0.7427984323843793),\n",
       " (114, 0.7448954997098681),\n",
       " (115, 0.746959814903182),\n",
       " (116, 0.7490003406741226),\n",
       " (117, 0.7510283239309405),\n",
       " (118, 0.7530252359169256),\n",
       " (119, 0.7550137217372099),\n",
       " (120, 0.756993449070971),\n",
       " (121, 0.7589460609960597),\n",
       " (122, 0.7608729252402118),\n",
       " (123, 0.7627906238935633),\n",
       " (124, 0.764681626978126),\n",
       " (125, 0.7665646005999919),\n",
       " (126, 0.7684197118152991),\n",
       " (127, 0.7702466741827111),\n",
       " (128, 0.7720730486912618),\n",
       " (129, 0.7738723130034129),\n",
       " (130, 0.7756669974235093),\n",
       " (131, 0.7774489697278825),\n",
       " (132, 0.7792080888356546),\n",
       " (133, 0.7809531191362845),\n",
       " (134, 0.782679268336481),\n",
       " (135, 0.7843969534304104),\n",
       " (136, 0.7860950369528967),\n",
       " (137, 0.7877830803921138),\n",
       " (138, 0.7894479690982309),\n",
       " (139, 0.7911055000126933),\n",
       " (140, 0.7927541092268457),\n",
       " (141, 0.7943842204379588),\n",
       " (142, 0.7960005173621054),\n",
       " (143, 0.7976069744703672),\n",
       " (144, 0.7991872892790757),\n",
       " (145, 0.8007669735148765),\n",
       " (146, 0.8023358179064198),\n",
       " (147, 0.8038984687744883),\n",
       " (148, 0.805440567558585),\n",
       " (149, 0.8069763340528664),\n",
       " (150, 0.8085105895325698),\n",
       " (151, 0.8100265547302236),\n",
       " (152, 0.8115204593981836),\n",
       " (153, 0.8130052041993893),\n",
       " (154, 0.8144878693233528),\n",
       " (155, 0.8159481697427261),\n",
       " (156, 0.8173976875533095),\n",
       " (157, 0.818837715777893),\n",
       " (158, 0.8202598389854971),\n",
       " (159, 0.8216758940744998),\n",
       " (160, 0.8230827628170453),\n",
       " (161, 0.8244870571737316),\n",
       " (162, 0.8258883646084262),\n",
       " (163, 0.8272869728505194),\n",
       " (164, 0.8286811096738129),\n",
       " (165, 0.8300709792576234),\n",
       " (166, 0.8314497890413084),\n",
       " (167, 0.8328271094506223),\n",
       " (168, 0.8341960010502671),\n",
       " (169, 0.8355551390304014),\n",
       " (170, 0.8368953803695297),\n",
       " (171, 0.8382297403508298),\n",
       " (172, 0.8395529954918283),\n",
       " (173, 0.840859851887839),\n",
       " (174, 0.8421619570650316),\n",
       " (175, 0.8434544577250704),\n",
       " (176, 0.8447387556681142),\n",
       " (177, 0.8460072786049236),\n",
       " (178, 0.8472640324598238),\n",
       " (179, 0.8485160558920082),\n",
       " (180, 0.8497467166122943),\n",
       " (181, 0.8509733424449152),\n",
       " (182, 0.8521871680194038),\n",
       " (183, 0.853395614202564),\n",
       " (184, 0.8545883550040395),\n",
       " (185, 0.8557744611208428),\n",
       " (186, 0.856953904172147),\n",
       " (187, 0.8581287978445593),\n",
       " (188, 0.8592952602422704),\n",
       " (189, 0.8604513497711244),\n",
       " (190, 0.8615956210612038),\n",
       " (191, 0.8627195877535707),\n",
       " (192, 0.8638388693871023),\n",
       " (193, 0.8649440703784704),\n",
       " (194, 0.8660418993675039),\n",
       " (195, 0.8671224435037018),\n",
       " (196, 0.8681880124315678),\n",
       " (197, 0.8692450414699634),\n",
       " (198, 0.870299228232563),\n",
       " (199, 0.8713452693817515),\n",
       " (200, 0.8723864960626656),\n",
       " (201, 0.8734138026850121),\n",
       " (202, 0.8744289393231777),\n",
       " (203, 0.8754369687276291),\n",
       " (204, 0.8764397856787104),\n",
       " (205, 0.8774311638557319),\n",
       " (206, 0.8784107542601571),\n",
       " (207, 0.8793881365781062),\n",
       " (208, 0.8803548776075654),\n",
       " (209, 0.8813182735849822),\n",
       " (210, 0.882267134920792),\n",
       " (211, 0.8832106745032857),\n",
       " (212, 0.8841440567325699),\n",
       " (213, 0.8850723552247731),\n",
       " (214, 0.8859929805305897),\n",
       " (215, 0.8868962371282108),\n",
       " (216, 0.8877973263469914),\n",
       " (217, 0.8886947549815433),\n",
       " (218, 0.8895825049214239),\n",
       " (219, 0.8904603114329831),\n",
       " (220, 0.8913314804065964),\n",
       " (221, 0.8921954671957296),\n",
       " (222, 0.8930542361456603),\n",
       " (223, 0.8938984754767051),\n",
       " (224, 0.894737009149722),\n",
       " (225, 0.8955701649854302),\n",
       " (226, 0.8963928606524864),\n",
       " (227, 0.8972085685469876),\n",
       " (228, 0.8980183476515091),\n",
       " (229, 0.8988192287532415),\n",
       " (230, 0.8996105127926577),\n",
       " (231, 0.9003973221330712),\n",
       " (232, 0.9011812401884668),\n",
       " (233, 0.901959192481773),\n",
       " (234, 0.9027279355178452),\n",
       " (235, 0.9034839535640362),\n",
       " (236, 0.9042319332020404),\n",
       " (237, 0.9049707051240606),\n",
       " (238, 0.9057060592521171),\n",
       " (239, 0.9064321135157655),\n",
       " (240, 0.9071461000503704),\n",
       " (241, 0.9078513213098885),\n",
       " (242, 0.9085528389602976),\n",
       " (243, 0.909249428696099),\n",
       " (244, 0.9099368783339591),\n",
       " (245, 0.9106216685068871),\n",
       " (246, 0.9113063639582148),\n",
       " (247, 0.9119798876561028),\n",
       " (248, 0.9126517622140409),\n",
       " (249, 0.9133181255199316),\n",
       " (250, 0.9139792048642096),\n",
       " (251, 0.9146326002186186),\n",
       " (252, 0.9152784144468501),\n",
       " (253, 0.9159180218231483),\n",
       " (254, 0.9165531310244494),\n",
       " (255, 0.9171828797362102),\n",
       " (256, 0.9178090787170791),\n",
       " (257, 0.9184302045880613),\n",
       " (258, 0.9190483103475685),\n",
       " (259, 0.9196555070075381),\n",
       " (260, 0.9202544655129438),\n",
       " (261, 0.9208482445287757),\n",
       " (262, 0.9214369620328267),\n",
       " (263, 0.9220203323444962),\n",
       " (264, 0.9225960281988765),\n",
       " (265, 0.9231697970742833),\n",
       " (266, 0.9237391790242138),\n",
       " (267, 0.9243055735010366),\n",
       " (268, 0.924869233150801),\n",
       " (269, 0.9254286535234988),\n",
       " (270, 0.9259802474556066),\n",
       " (271, 0.9265267255361617),\n",
       " (272, 0.9270698842258533),\n",
       " (273, 0.9276105169572894),\n",
       " (274, 0.9281487272708769),\n",
       " (275, 0.9286802387906379),\n",
       " (276, 0.9292108192650633),\n",
       " (277, 0.9297365423767451),\n",
       " (278, 0.9302586258709943),\n",
       " (279, 0.9307744686351244),\n",
       " (280, 0.9312859584506997),\n",
       " (281, 0.9317948848251053),\n",
       " (282, 0.9322990841031549),\n",
       " (283, 0.93280100428043),\n",
       " (284, 0.9332982567569332),\n",
       " (285, 0.9337911749696477),\n",
       " (286, 0.9342835582102558),\n",
       " (287, 0.9347689008976244),\n",
       " (288, 0.9352525798723265),\n",
       " (289, 0.9357333202737347),\n",
       " (290, 0.9362046227989936),\n",
       " (291, 0.9366730353452729),\n",
       " (292, 0.9371331908037747),\n",
       " (293, 0.9375928911079906),\n",
       " (294, 0.938043545858587),\n",
       " (295, 0.9384907498709161),\n",
       " (296, 0.9389356912838306),\n",
       " (297, 0.9393791581373204),\n",
       " (298, 0.9398138751079695),\n",
       " (299, 0.9402460441967735),\n",
       " (300, 0.9406732653868731),\n",
       " (301, 0.9411001271245018),\n",
       " (302, 0.9415252238718084),\n",
       " (303, 0.9419478474492012),\n",
       " (304, 0.9423672221173536),\n",
       " (305, 0.9427818787873691),\n",
       " (306, 0.943191287886209),\n",
       " (307, 0.9435959149794539),\n",
       " (308, 0.9439990776149911),\n",
       " (309, 0.9443987204295754),\n",
       " (310, 0.9447922125777485),\n",
       " (311, 0.9451831231576913),\n",
       " (312, 0.9455738347788419),\n",
       " (313, 0.9459628179944914),\n",
       " (314, 0.9463479426852273),\n",
       " (315, 0.9467323544469616),\n",
       " (316, 0.9471089923488045),\n",
       " (317, 0.9474845854548178),\n",
       " (318, 0.9478593147013828),\n",
       " (319, 0.9482331664478412),\n",
       " (320, 0.9486016864341369),\n",
       " (321, 0.9489667390734573),\n",
       " (322, 0.9493299813932022),\n",
       " (323, 0.9496885868470718),\n",
       " (324, 0.9500453633979464),\n",
       " (325, 0.9504004484548826),\n",
       " (326, 0.950753242626629),\n",
       " (327, 0.9511010361339745),\n",
       " (328, 0.9514473637062569),\n",
       " (329, 0.9517912864818955),\n",
       " (330, 0.9521310328736982),\n",
       " (331, 0.9524690063032982),\n",
       " (332, 0.952802042061862),\n",
       " (333, 0.9531344733600263),\n",
       " (334, 0.9534647252725682),\n",
       " (335, 0.9537911600111911),\n",
       " (336, 0.9541151832493204),\n",
       " (337, 0.9544361702530066),\n",
       " (338, 0.9547565330944701),\n",
       " (339, 0.955076120234862),\n",
       " (340, 0.9553911872350608),\n",
       " (341, 0.9557046180603527),\n",
       " (342, 0.9560167710363912),\n",
       " (343, 0.9563241249312431),\n",
       " (344, 0.956631079576056),\n",
       " (345, 0.9569355135679335),\n",
       " (346, 0.9572383855164233),\n",
       " (347, 0.9575367566692958),\n",
       " (348, 0.9578341333756445),\n",
       " (349, 0.958130260825018),\n",
       " (350, 0.958424597774238),\n",
       " (351, 0.9587151176143921),\n",
       " (352, 0.9590029209405866),\n",
       " (353, 0.9592888670562666),\n",
       " (354, 0.9595738013711731),\n",
       " (355, 0.9598554997534698),\n",
       " (356, 0.9601352785079958),\n",
       " (357, 0.9604137488827437),\n",
       " (358, 0.9606914817375619),\n",
       " (359, 0.9609684960644086),\n",
       " (360, 0.9612435702709242),\n",
       " (361, 0.9615176750843873),\n",
       " (362, 0.9617864117621996),\n",
       " (363, 0.9620524881376414),\n",
       " (364, 0.9623180951744286),\n",
       " (365, 0.9625802219356442),\n",
       " (366, 0.9628399839812978),\n",
       " (367, 0.9630977788064787),\n",
       " (368, 0.963353146336546),\n",
       " (369, 0.9636073422377737),\n",
       " (370, 0.9638588109794622),\n",
       " (371, 0.9641078380592877),\n",
       " (372, 0.9643558693941463),\n",
       " (373, 0.9646028422821344),\n",
       " (374, 0.9648488795350628),\n",
       " (375, 0.96509093475692),\n",
       " (376, 0.9653319723865353),\n",
       " (377, 0.9655717377477292),\n",
       " (378, 0.9658097582594389),\n",
       " (379, 0.9660463826493535),\n",
       " (380, 0.966281595848674),\n",
       " (381, 0.9665146406860573),\n",
       " (382, 0.9667453516419755),\n",
       " (383, 0.9669745531722072),\n",
       " (384, 0.9672033151203361),\n",
       " (385, 0.9674303836772054),\n",
       " (386, 0.9676572767716549),\n",
       " (387, 0.9678821222381905),\n",
       " (388, 0.9681051302268947),\n",
       " (389, 0.9683276163684702),\n",
       " (390, 0.9685482488548471),\n",
       " (391, 0.9687666476704527),\n",
       " (392, 0.9689845420070535),\n",
       " (393, 0.9692007110682376),\n",
       " (394, 0.9694163795318094),\n",
       " (395, 0.9696309934806261),\n",
       " (396, 0.9698436831805123),\n",
       " (397, 0.9700556306589573),\n",
       " (398, 0.9702653657559999),\n",
       " (399, 0.9704733705997192),\n",
       " (400, 0.9706799415676863),\n",
       " (401, 0.9708858630458368),\n",
       " (402, 0.9710900628061391),\n",
       " (403, 0.9712925336867154),\n",
       " (404, 0.9714940724601613),\n",
       " (405, 0.9716952813629984),\n",
       " (406, 0.9718941426907056),\n",
       " (407, 0.9720923049246718),\n",
       " (408, 0.9722887852132613),\n",
       " (409, 0.9724842937430523),\n",
       " (410, 0.9726779911326765),\n",
       " (411, 0.9728704713110821),\n",
       " (412, 0.9730621068148593),\n",
       " (413, 0.973253090870755),\n",
       " (414, 0.9734434339008777),\n",
       " (415, 0.9736321615964976),\n",
       " (416, 0.9738202031436056),\n",
       " (417, 0.9740062768053132),\n",
       " (418, 0.9741919769983879),\n",
       " (419, 0.9743746453284525),\n",
       " (420, 0.9745555272084658),\n",
       " (421, 0.9747344001909688),\n",
       " (422, 0.9749128104073478),\n",
       " (423, 0.975089931540225),\n",
       " (424, 0.9752665700003674),\n",
       " (425, 0.9754418565010936),\n",
       " (426, 0.975616752938695),\n",
       " (427, 0.9757904518321924),\n",
       " (428, 0.9759620748260314),\n",
       " (429, 0.9761331516430829),\n",
       " (430, 0.9763034512040423),\n",
       " (431, 0.9764728615479568),\n",
       " (432, 0.976641528943591),\n",
       " (433, 0.9768097723204251),\n",
       " (434, 0.9769764118001784),\n",
       " (435, 0.9771426562928514),\n",
       " (436, 0.9773084808594925),\n",
       " (437, 0.9774734474562687),\n",
       " (438, 0.9776366952081834),\n",
       " (439, 0.9777999078162601),\n",
       " (440, 0.9779621286774559),\n",
       " (441, 0.9781239610701205),\n",
       " (442, 0.9782834159076279),\n",
       " (443, 0.9784417306388826),\n",
       " (444, 0.9785990583806504),\n",
       " (445, 0.978755718047765),\n",
       " (446, 0.9789100220544033),\n",
       " (447, 0.979064060961678),\n",
       " (448, 0.9792176861683588),\n",
       " (449, 0.979370507658266),\n",
       " (450, 0.9795221539079922),\n",
       " (451, 0.9796720093966852),\n",
       " (452, 0.9798214412769022),\n",
       " (453, 0.9799703180720427),\n",
       " (454, 0.9801184525625919),\n",
       " (455, 0.9802657605596664),\n",
       " (456, 0.9804120600816614),\n",
       " (457, 0.9805573132705789),\n",
       " (458, 0.9807018924909943),\n",
       " (459, 0.9808458002442694),\n",
       " (460, 0.9809881915622541),\n",
       " (461, 0.9811302967182715),\n",
       " (462, 0.9812708391973616),\n",
       " (463, 0.9814108074312586),\n",
       " (464, 0.9815501485472581),\n",
       " (465, 0.98168909848733),\n",
       " (466, 0.9818275860832061),\n",
       " (467, 0.9819656769076852),\n",
       " (468, 0.9821031164400004),\n",
       " (469, 0.9822393328550398),\n",
       " (470, 0.9823748742644641),\n",
       " (471, 0.9825098938644417),\n",
       " (472, 0.9826437475229841),\n",
       " (473, 0.982777212581243),\n",
       " (474, 0.9829100159378867),\n",
       " (475, 0.9830420215627156),\n",
       " (476, 0.9831736794430529),\n",
       " (477, 0.9833044323460681),\n",
       " (478, 0.9834348227379811),\n",
       " (479, 0.9835648335672542),\n",
       " (480, 0.983694411741871),\n",
       " (481, 0.9838236151812466),\n",
       " (482, 0.9839500290371076),\n",
       " (483, 0.9840759405241549),\n",
       " (484, 0.9842007502492678),\n",
       " (485, 0.9843251727674592),\n",
       " (486, 0.9844493265264438),\n",
       " (487, 0.9845725224790252),\n",
       " (488, 0.9846951958464678),\n",
       " (489, 0.9848171280721804),\n",
       " (490, 0.9849385823795467),\n",
       " (491, 0.9850592095386782),\n",
       " (492, 0.9851793436874378),\n",
       " (493, 0.9852988779977415),\n",
       " (494, 0.9854179644488789),\n",
       " (495, 0.9855359052796498),\n",
       " (496, 0.98565327677022),\n",
       " (497, 0.9857697698058935),\n",
       " (498, 0.9858857981096019),\n",
       " (499, 0.9860011172847416),\n",
       " (500, 0.9861158344288393),\n",
       " (501, 0.9862300889668474),\n",
       " (502, 0.9863435014214019),\n",
       " (503, 0.9864564691456489),\n",
       " (504, 0.9865684372878863),\n",
       " (505, 0.9866801382538783),\n",
       " (506, 0.9867914287285141),\n",
       " (507, 0.9869020212315271),\n",
       " (508, 0.9870116356571242),\n",
       " (509, 0.9871208776902681),\n",
       " (510, 0.9872295210955451),\n",
       " (511, 0.9873375921714291),\n",
       " (512, 0.9874455682501564),\n",
       " (513, 0.9875527127934561),\n",
       " (514, 0.9876595101117783),\n",
       " (515, 0.9877657035832232),\n",
       " (516, 0.9878717299705869),\n",
       " (517, 0.9879768248007863),\n",
       " (518, 0.9880812007204876),\n",
       " (519, 0.9881854618010244),\n",
       " (520, 0.9882893300814792),\n",
       " (521, 0.9883930754952459),\n",
       " (522, 0.9884954908076482),\n",
       " (523, 0.9885976487833894),\n",
       " (524, 0.988699247973743),\n",
       " (525, 0.9888002739951237),\n",
       " (526, 0.9889005542046637),\n",
       " (527, 0.9890002191919562),\n",
       " (528, 0.9890995967807455),\n",
       " (529, 0.989198623647948),\n",
       " (530, 0.9892965454226161),\n",
       " (531, 0.9893942038243234),\n",
       " (532, 0.9894915833299992),\n",
       " (533, 0.9895881641117573),\n",
       " (534, 0.9896841762148774),\n",
       " (535, 0.9897798987635801),\n",
       " (536, 0.9898752526300347),\n",
       " (537, 0.9899699645903721),\n",
       " (538, 0.9900644006822079),\n",
       " (539, 0.9901587242355676),\n",
       " (540, 0.9902522067687263),\n",
       " (541, 0.9903448128400545),\n",
       " (542, 0.9904370865046203),\n",
       " (543, 0.9905285748383684),\n",
       " (544, 0.9906195587050189),\n",
       " (545, 0.9907104614426827),\n",
       " (546, 0.9908006005177198),\n",
       " (547, 0.9908902089261736),\n",
       " (548, 0.9909790160579335),\n",
       " (549, 0.9910672745047572),\n",
       " (550, 0.9911550286436156),\n",
       " (551, 0.9912424962482329),\n",
       " (552, 0.9913296071368171),\n",
       " (553, 0.9914157155439413),\n",
       " (554, 0.9915014881058386),\n",
       " (555, 0.991586813891608),\n",
       " (556, 0.9916720763249255),\n",
       " (557, 0.9917564875362139),\n",
       " (558, 0.9918405862841322),\n",
       " (559, 0.9919241801037787),\n",
       " (560, 0.9920073695463595),\n",
       " (561, 0.9920898690330946),\n",
       " (562, 0.9921715715365729),\n",
       " (563, 0.9922531115755032),\n",
       " (564, 0.9923339704035354),\n",
       " (565, 0.9924146500168822),\n",
       " (566, 0.9924948870312239),\n",
       " (567, 0.9925746670436575),\n",
       " (568, 0.9926535272524052),\n",
       " (569, 0.9927322890488693),\n",
       " (570, 0.9928106099413567),\n",
       " (571, 0.9928883802369827),\n",
       " (572, 0.9929659612409928),\n",
       " (573, 0.9930433091924222),\n",
       " (574, 0.9931199712258344),\n",
       " (575, 0.9931963634275887),\n",
       " (576, 0.99327211623988),\n",
       " (577, 0.9933477141917129),\n",
       " (578, 0.9934229280375387),\n",
       " (579, 0.9934979682754256),\n",
       " (580, 0.9935721310607158),\n",
       " (581, 0.9936459635705103),\n",
       " (582, 0.9937193862932602),\n",
       " (583, 0.9937924174008108),\n",
       " (584, 0.9938650212389489),\n",
       " (585, 0.9939371488997251),\n",
       " (586, 0.9940091116108476),\n",
       " (587, 0.994080257824569),\n",
       " (588, 0.9941510199245274),\n",
       " (589, 0.9942208157202439),\n",
       " (590, 0.9942903397373887),\n",
       " (591, 0.994359682348669),\n",
       " (592, 0.994428475819754),\n",
       " (593, 0.9944969734773312),\n",
       " (594, 0.9945649390157029),\n",
       " (595, 0.994632664587523),\n",
       " (596, 0.9947002656580635),\n",
       " (597, 0.9947672726611538),\n",
       " (598, 0.9948341558278948),\n",
       " (599, 0.99490080601303),\n",
       " (600, 0.9949667773451522),\n",
       " (601, 0.9950323818284414),\n",
       " (602, 0.9950972920314762),\n",
       " (603, 0.9951619280631243),\n",
       " (604, 0.9952262792805363),\n",
       " (605, 0.9952905733094631),\n",
       " (606, 0.9953539954479448),\n",
       " (607, 0.9954170991128147),\n",
       " (608, 0.9954800693252376),\n",
       " (609, 0.9955425561143804),\n",
       " (610, 0.9956044403767357),\n",
       " (611, 0.9956660041510512),\n",
       " (612, 0.9957270251080838),\n",
       " (613, 0.9957877087516265),\n",
       " (614, 0.9958483016340625),\n",
       " (615, 0.9959086881007762),\n",
       " (616, 0.9959685478460332),\n",
       " (617, 0.9960281563298568),\n",
       " (618, 0.9960871645025638),\n",
       " (619, 0.9961460299786852),\n",
       " (620, 0.9962045824006011),\n",
       " (621, 0.9962628693400362),\n",
       " (622, 0.9963208637121475),\n",
       " (623, 0.9963785328404443),\n",
       " (624, 0.9964359786291643),\n",
       " (625, 0.9964932439383767),\n",
       " (626, 0.9965500434371231),\n",
       " (627, 0.9966066506483496),\n",
       " (628, 0.996662913453358),\n",
       " (629, 0.9967189516686159),\n",
       " (630, 0.9967746840569388),\n",
       " (631, 0.9968301405470736),\n",
       " (632, 0.9968854432106627),\n",
       " (633, 0.9969403452138245),\n",
       " (634, 0.9969947883400073),\n",
       " (635, 0.9970488692110958),\n",
       " (636, 0.997102719034395),\n",
       " (637, 0.9971561144827152),\n",
       " (638, 0.997209448985931),\n",
       " (639, 0.9972621244514052),\n",
       " (640, 0.9973144514077332),\n",
       " (641, 0.997366414669407),\n",
       " (642, 0.997418199488819),\n",
       " (643, 0.9974694544884634),\n",
       " (644, 0.9975203009569602),\n",
       " (645, 0.9975709303179895),\n",
       " (646, 0.9976211143673831),\n",
       " (647, 0.9976711135520643),\n",
       " (648, 0.9977205343948163),\n",
       " (649, 0.9977698173074292),\n",
       " (650, 0.9978187047159662),\n",
       " (651, 0.9978675258091566),\n",
       " (652, 0.9979159696329595),\n",
       " (653, 0.9979641688411691),\n",
       " (654, 0.9980118999522852),\n",
       " (655, 0.9980594308835695),\n",
       " (656, 0.9981064950187605),\n",
       " (657, 0.9981529373229638),\n",
       " (658, 0.9981991873313273),\n",
       " (659, 0.9982453331682579),\n",
       " (660, 0.9982911268363692),\n",
       " (661, 0.9983362649729071),\n",
       " (662, 0.9983812509737781),\n",
       " (663, 0.9984260856387965),\n",
       " (664, 0.998470374723121),\n",
       " (665, 0.9985143585845968),\n",
       " (666, 0.998557911664892),\n",
       " (667, 0.9986013733469792),\n",
       " (668, 0.9986441656550357),\n",
       " (669, 0.9986868112866086),\n",
       " (670, 0.9987287189203747),\n",
       " (671, 0.9987704759818921),\n",
       " (672, 0.998812031838754),\n",
       " (673, 0.9988531891558402),\n",
       " (674, 0.9988939722364083),\n",
       " (675, 0.9989342947047175),\n",
       " (676, 0.9989744375244171),\n",
       " (677, 0.9990141620357069),\n",
       " (678, 0.9990535213038514),\n",
       " (679, 0.9990925542127775),\n",
       " (680, 0.9991314227741327),\n",
       " (681, 0.9991699411381345),\n",
       " (682, 0.9992081397746686),\n",
       " (683, 0.9992459692290702),\n",
       " (684, 0.9992835852143942),\n",
       " (685, 0.9993206562536758),\n",
       " (686, 0.9993573663953446),\n",
       " (687, 0.9993936451672814),\n",
       " (688, 0.999429513035175),\n",
       " (689, 0.9994648431658018),\n",
       " (690, 0.9994998221579028),\n",
       " (691, 0.999534503846584),\n",
       " (692, 0.9995687012955773),\n",
       " (693, 0.9996025127526901),\n",
       " (694, 0.999636129784443),\n",
       " (695, 0.9996694212478501),\n",
       " (696, 0.9997023583143568),\n",
       " (697, 0.9997346931586247),\n",
       " (698, 0.9997668719203138),\n",
       " (699, 0.9997978312280766),\n",
       " (700, 0.999828051680832),\n",
       " (701, 0.9998581149150447),\n",
       " (702, 0.9998876737890163),\n",
       " (703, 0.9999159894756505),\n",
       " (704, 0.999942296605259),\n",
       " (705, 0.9999679746048438),\n",
       " (706, 0.9999933206292906),\n",
       " (707, 0.9999999999999996),\n",
       " (708, 0.9999999999999996),\n",
       " (709, 0.9999999999999996),\n",
       " (710, 0.9999999999999996),\n",
       " (711, 0.9999999999999996),\n",
       " (712, 0.9999999999999996),\n",
       " (713, 0.9999999999999996),\n",
       " (714, 0.9999999999999996),\n",
       " (715, 0.9999999999999996),\n",
       " (716, 0.9999999999999996),\n",
       " (717, 0.9999999999999996),\n",
       " (718, 0.9999999999999996),\n",
       " (719, 0.9999999999999996),\n",
       " (720, 0.9999999999999996),\n",
       " (721, 0.9999999999999996),\n",
       " (722, 0.9999999999999996),\n",
       " (723, 0.9999999999999996),\n",
       " (724, 0.9999999999999996),\n",
       " (725, 0.9999999999999996),\n",
       " (726, 0.9999999999999996),\n",
       " (727, 0.9999999999999996),\n",
       " (728, 0.9999999999999996),\n",
       " (729, 0.9999999999999996),\n",
       " (730, 0.9999999999999996),\n",
       " (731, 0.9999999999999996),\n",
       " (732, 0.9999999999999996),\n",
       " (733, 0.9999999999999996),\n",
       " (734, 0.9999999999999996),\n",
       " (735, 0.9999999999999996),\n",
       " (736, 0.9999999999999996),\n",
       " (737, 0.9999999999999996),\n",
       " (738, 0.9999999999999996),\n",
       " (739, 0.9999999999999996),\n",
       " (740, 0.9999999999999996),\n",
       " (741, 0.9999999999999996),\n",
       " (742, 0.9999999999999996),\n",
       " (743, 0.9999999999999996),\n",
       " (744, 0.9999999999999996),\n",
       " (745, 0.9999999999999996),\n",
       " (746, 0.9999999999999996),\n",
       " (747, 0.9999999999999996),\n",
       " (748, 0.9999999999999996),\n",
       " (749, 0.9999999999999996),\n",
       " (750, 0.9999999999999996),\n",
       " (751, 0.9999999999999996),\n",
       " (752, 0.9999999999999996),\n",
       " (753, 0.9999999999999996),\n",
       " (754, 0.9999999999999996),\n",
       " (755, 0.9999999999999996),\n",
       " (756, 0.9999999999999996),\n",
       " (757, 0.9999999999999996),\n",
       " (758, 0.9999999999999996),\n",
       " (759, 0.9999999999999996),\n",
       " (760, 0.9999999999999996),\n",
       " (761, 0.9999999999999996),\n",
       " (762, 0.9999999999999996),\n",
       " (763, 0.9999999999999996),\n",
       " (764, 0.9999999999999996),\n",
       " (765, 0.9999999999999996),\n",
       " (766, 0.9999999999999996),\n",
       " (767, 0.9999999999999996),\n",
       " (768, 0.9999999999999996),\n",
       " (769, 0.9999999999999996),\n",
       " (770, 0.9999999999999996),\n",
       " (771, 0.9999999999999996),\n",
       " (772, 0.9999999999999996),\n",
       " (773, 0.9999999999999996),\n",
       " (774, 0.9999999999999996),\n",
       " (775, 0.9999999999999996),\n",
       " (776, 0.9999999999999996),\n",
       " (777, 0.9999999999999996),\n",
       " (778, 0.9999999999999996),\n",
       " (779, 0.9999999999999996),\n",
       " (780, 0.9999999999999996),\n",
       " (781, 0.9999999999999996),\n",
       " (782, 0.9999999999999996),\n",
       " (783, 0.9999999999999996)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(np.cumsum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4b635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
